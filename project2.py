# -*- coding: utf-8 -*-
"""Project2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1R0BsQSma4u4-uOw2NgRqXfQsmsB8BJp7
"""

import torch
from torch import nn
import numpy as np

class Linear(torch.nn.Module):
  def __init__(self, in_features: int, out_features: int, bias: bool = True, device=None, dtype=None) -> None:
    factory_kwargs = {'device': device, 'dtype': dtype}
    super(Linear, self).__init__()
    self.in_features = in_features
    self.out_features = out_features
    self.weight = nn.Parameter(torch.empty((out_features, in_features), **factory_kwargs))
    if bias:
        self.bias = nn.Parameter(torch.empty(out_features, **factory_kwargs))
    else:
        self.register_parameter('bias', None)
    self.reset_parameters()

  def reset_parameters(self) -> None:
    self.weight = nn.Parameter(torch.rand([self.out_features, self.in_features]))
    if self.bias is not None:
      self.bias = nn.Parameter(torch.rand([self.out_features]))

  def forward(self, input: torch.Tensor) -> torch.Tensor:
    return torch.matmul(input, torch.transpose(self.weight,0,1)) + self.bias

  def extra_repr(self) -> str:
    return 'in_features={}, out_features={}, bias={}'.format(
        self.in_features, self.out_features, self.bias is not None
      )

class BTU(torch.nn.Module):
  def __init__(self, T=0.2, inplace: bool = False):
      super(BTU, self).__init__()
      self.T = T

  def forward(self, input: torch.Tensor) -> torch.Tensor:
      return 1 / (1 + torch.exp(-input/self.T))

class XOR_Net_Model(nn.Module):
  def __init__(self,dim=2, num_hidden=2, out_dim=1,  bypass=False):
    super().__init__()
    self.bypass = bypass
    self.hidden = Linear(dim, num_hidden)
    if self.bypass:
      self.output = Linear(num_hidden + dim, out_dim)
    else:
      self.output = Linear(num_hidden, out_dim)
    self.BTU = BTU(0.5)

  def forward(self, input, print_hidden= False):
    z1 = self.hidden(input)
    y1 = self.BTU(z1)
    if print_hidden:
      print(torch.cat((input, y1), 1))

    if self.bypass:
      y1_concat = torch.cat((input, y1), 1)
      z2 = self.output(y1_concat)
    else:
      z2 = self.output(y1)
    return self.BTU(z2)

def Loss(out, t_train):
  return -torch.sum(t_train * torch.log(out) + (1.0 - t_train) * torch.log(1.0 - out))  # Cross Entropy loss function

def train(model, x_train, t_train, optimizer):
  y_pred = model(x_train)
  loss = Loss(y_pred, t_train)

  # zero gradients berfore running the backward pass
  optimizer.zero_grad()

  # backward pass to compute the gradient of loss
  # backprop + accumulate
  loss.backward()

  # update params
  optimizer.step()
  return loss

def experiment(l_rate: float, hidden: int, bypass:bool = False, print_hidden= False):
  counter = 0
  result = {"failed": 0}

  while(counter != 10):
    model = XOR_Net_Model(num_hidden=hidden, bypass=bypass)
    x_train = torch.tensor([[0, 0], [0, 1], [1, 0], [1, 1]], requires_grad=True, dtype=torch.float32)
    t_train = torch.tensor([[0], [1], [1], [0]], dtype=torch.float32)

    v_train = torch.tensor([[0, 0], [0, 1], [1, 0], [1, 1], [1, 0.1], [1, 0.9], [0.9, 0.9], [0.1, 0.9]], requires_grad=True, dtype=torch.float32)
    v_t_train = torch.tensor([[0], [1], [1], [0], [1], [0], [0], [1]], dtype=torch.float32)

    num_epocs = 40000

    optimizer = torch.optim.SGD(model.parameters(), lr=l_rate)
    queue = []
    success = False

    for i in range(num_epocs):
      train_loss = train(model, x_train, t_train, optimizer)
      validation_loss = Loss(model(v_train), v_t_train)

      if len(queue) > 10:
        queue.pop(0)

      queue.append(validation_loss)
      if validation_loss < 0.2 and (queue[0] - queue[-1]) < 0.0001:
        success = True
        break

    if success is True:
      result[counter] = {'epochs': i, 'validation_loss': validation_loss.item(), 'train_loss': train_loss.item()}
      counter += 1
      if print_hidden:
        model(x_train, print_hidden=True)
        print("---------------")

    else:
      result['failed'] += 1

  return result

def calculate_experiment_std_mean(results: dict):
  epochs = []
  validation_loss = []
  train_loss = []
  fails = results['failed']
  results.pop('failed', None)

  for key, res in results.items():
    epochs.append(res['epochs'])
    validation_loss.append(res['validation_loss'])
    train_loss.append(res['train_loss'])

  return {'epochs_std_mean': (np.std(epochs), np.mean(epochs)),
          'validation_loss_std_mean': (np.std(validation_loss), np.mean(validation_loss)),
          'train_loss_std_mean': (np.std(train_loss), np.mean(train_loss)),
          'failed': fails}

print("Learning Rate: 0.1, Hidden: 2, bypass: False \n", calculate_experiment_std_mean(experiment(l_rate=0.1, hidden=2, bypass=False)))
print("Learning Rate: 0.1, Hidden: 2, bypass: True \n", calculate_experiment_std_mean(experiment(l_rate=0.1, hidden=2, bypass=True)))
print("Learning Rate: 0.1, Hidden: 4, bypass: False \n", calculate_experiment_std_mean(experiment(l_rate=0.1, hidden=4, bypass=False)))
print("Learning Rate: 0.1, Hidden: 4, bypass: True \n", calculate_experiment_std_mean(experiment(l_rate=0.1, hidden=4, bypass=True)))

print("Learning Rate: 0.1, Hidden: 3, bypass: True \n", calculate_experiment_std_mean(experiment(l_rate=0.1, hidden=3, bypass=True)))
print("Learning Rate: 0.1, Hidden: 3, bypass: False \n", calculate_experiment_std_mean(experiment(l_rate=0.1, hidden=3, bypass=False)))

print("Learning Rate: 0.01, Hidden: 2, bypass: False \n", calculate_experiment_std_mean(experiment(l_rate=0.01, hidden=2, bypass=False)))
print("Learning Rate: 0.01, Hidden: 2, bypass: True \n", calculate_experiment_std_mean(experiment(l_rate=0.01, hidden=2, bypass=True)))
print("Learning Rate: 0.01, Hidden: 4, bypass: False \n", calculate_experiment_std_mean(experiment(l_rate=0.01, hidden=4, bypass=False)))
print("Learning Rate: 0.01, Hidden: 4, bypass: True \n", calculate_experiment_std_mean(experiment(l_rate=0.01, hidden=4, bypass=True)))

print("Learning Rate: 0.01, Hidden: 3, bypass: True \n", calculate_experiment_std_mean(experiment(l_rate=0.01, hidden=3, bypass=True)))
print("Learning Rate: 0.01, Hidden: 3, bypass: False \n", calculate_experiment_std_mean(experiment(l_rate=0.01, hidden=3, bypass=False)))

print("Learning Rate: 0.1, Hidden: 1, bypass: True \n", calculate_experiment_std_mean(experiment(l_rate=0.1, hidden=1, bypass=True, print_hidden=True)))